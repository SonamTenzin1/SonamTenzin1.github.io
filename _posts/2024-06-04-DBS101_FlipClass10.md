---
Title: DBS101 Flipped Class 10
categories: [DBS101, Flipped_Class]
tags: [DBS101]
---

### Topic: Recovery Algorithms

Recovery algorithms in databases are a set of techniques that databases use to ensure data consistency and accessibility even in the face of failures. These failures can come in many forms, such as power outages, hardware malfunctions, software bugs, or even human errors. The goal of recovery algorithms is to bring the database back to a consistent state, meaning that all data updates follow the proper order and no incomplete transactions are left hanging.

There are two main parts to recovery algorithms:

1. **Actions during normal transaction processing:** These involve techniques used while the database is functioning normally to prepare for potential failures in the future. This might involve writing transaction logs or creating checkpoints in the database.

2. **Actions after a failure:** These are the steps taken to recover the database after a failure has occurred. This typically involves using the transaction logs or checkpoints created earlier to undo incomplete transactions and replay completed ones.

Here are some of the common recovery algorithms used in databases:

* **Write-Ahead Logging (WAL):** This is a popular technique where all database changes are first written to a transaction log before being applied to the actual data files. This ensures that even if a failure occurs during a transaction, the database can be restored to a consistent state by replaying the completed transactions from the log.

* **Checkpointing:** This involves periodically taking a snapshot of the database state and storing it in a safe location. In case of a failure, the database can be recovered to this checkpoint and then replay the transactions that occurred since the checkpoint was taken.

* **Redo/Undo recovery:** This technique uses the transaction log to determine which transactions were completed and which were not. Completed transactions are "redone" to bring the database to the state it should be in, while incomplete transactions are "undone" to prevent corrupt data.

By implementing these recovery algorithms, databases can ensure the integrity and availability of your data, even in the face of unexpected disruptions.

One of the most popular algorithm is ARIES. It stands for **Algebraic Recovery In Equity Systems**. It's a specific implementation of a recovery algorithm used in transaction databases, most notably in PostgreSQL. It's a write-ahead logging (WAL) based technique that ensures data consistency and atomicity (all-or-nothing) in transactions even in case of failures.

Key features:

* **Write-Ahead Logging (WAL):**  Like other WAL-based recovery algorithms, ARIES relies on a transaction log to track all database modifications. Before any changes are applied to the actual data files, they are first written to the WAL. This ensures that even if a failure occurs during a transaction, the database can be restored to a consistent state by replaying the completed transactions from the log.

* **Checkpointing:** ARIES utilizes checkpoints periodically. These checkpoints represent a consistent state of the database at a specific point in time. They act as a reference point for recovery, allowing the database to be restored to the state captured in the checkpoint and then replay the transactions that occurred since.

* **Redo and Undo Logging:** ARIES leverages the transaction log to differentiate between completed and incomplete transactions. It uses two key operations for recovery:
    * **Redo:**  For transactions marked as committed in the log, a redo operation replays the changes to bring the database to the intended final state.
    * **Undo:**  For transactions marked as uncommitted in the log, an undo operation reverses any changes made, ensuring the database remains in a consistent state.

ARIES is known for its efficiency and reliability. It's a robust algorithm that can handle various failure scenarios, minimizing data loss and ensuring database integrity. It's a core component of PostgreSQL's recovery mechanism and contributes to its reputation as a dependable database management system.

Another recovery algorithm used in databases besides ARIES is **Shadow Paging**. This technique also focuses on ensuring data consistency after failures but takes a different approach.

Here's how Shadow Paging works:

1. **Data and Redo Page:** Instead of a single data file, Shadow Paging uses two copies: the original data page and a "shadow page." The original data page holds the actual data, while the shadow page acts as a temporary buffer for ongoing modifications.

2. **Transaction Processing:** During a transaction, changes are first written to the in-memory buffer. Once the transaction is complete and committed, the updated data from the buffer is flushed to the shadow page.

3. **Checkpoint:** Periodically, checkpoints are taken. During a checkpoint, the shadow page becomes the new active data page, and a fresh shadow page is allocated. This essentially creates a consistent snapshot of the database at that point.

4. **Recovery:** In case of a failure, the system checks the transaction log to identify any uncommitted transactions. Any changes associated with these uncommitted transactions in the shadow page are simply discarded. This ensures only completed and committed transactions are reflected in the active data page.

**Benefits of Shadow Paging:**

* **Faster Writes:** Since modifications happen in the memory buffer first, writes are generally faster compared to WAL-based techniques like ARIES.
* **Reduced Write Amplification:** By writing to a separate shadow page before updating the main data page, Shadow Paging can minimize the need to rewrite entire data blocks, reducing write amplification.

**Drawbacks of Shadow Paging:**

* **Increased Complexity:** Managing two data pages and keeping them synchronized can add complexity to the database system.
* **Potential Data Loss:** If a failure occurs before the shadow page is flushed to the main data page, some committed transactions might be lost.

**Use Cases:**

Shadow Paging is often used in real-time systems where fast write performance is crucial. However, due to the potential for data loss, it's sometimes combined with other recovery techniques like WAL for added reliability.

## Recovery Algorithms in Databases: ARIES vs Shadow Paging

| Feature                 | ARIES (Write-Ahead Logging) | Shadow Paging                 |
|--------------------------|----------------------------|-------------------------------|
| Logging Mechanism       | Write-Ahead Logging (WAL)  | Separate Data & Redo Pages      |
| Data Modification       | Logged before applied to data files | Written to memory buffer first   |
| Transaction Redo/Undo  | Uses redo/undo operations on transaction log | Discards uncommitted changes from shadow page |
| Checkpointing           | Periodic snapshots for recovery reference | Periodic snapshots with shadow page becoming active data page |
| Data Consistency        | Ensured by replaying committed transactions from WAL | Ensured by discarding uncommitted changes from shadow page |
| Write Performance       | Slower due to WAL writes before data updates | Faster due to initial memory buffer writes |
| Write Amplification     | Can be higher due to more writes (WAL & data) | Potentially lower due to less frequent data page updates |
| Complexity               | Less complex, well-established technique | More complex due to managing two data pages |
| Data Loss Risk           | Lower, uncommitted transactions not reflected in data files | Higher, potential loss of committed data if shadow page not flushed |
| Use Cases                | General-purpose databases prioritizing data integrity | Real-time systems prioritizing write performance (often combined with WAL for reliability) |

### Database logging

Database logging refers to the process of recording events and activities that happen within a database management system (DBMS). These logs  serve several purposes, including:

* **Monitoring and troubleshooting:**  Database logs provide valuable insights into how the database is performing. They can help identify issues like slow queries, connection errors, or unusual access patterns. By analyzing these logs, database administrators can diagnose problems, optimize performance, and ensure the smooth operation of the database.

* **Security and auditing:** Database logs can track user activity and record any attempts to access or modify data. This information is crucial for maintaining database security and detecting potential unauthorized access or malicious activity. Logs can help identify suspicious login attempts, data breaches, or attempts to tamper with data.

* **Data recovery and rollbacks:** In case of a database failure or corruption, database logs can be used to recover data or rollback transactions.  The logs track the sequence of changes made to the database, allowing administrators to restore the database to a known good state. For instance, if you accidentally delete some data, you might be able to recover it by looking at the logs and replaying the actions that led to its creation.

Here's a breakdown of the different types of database logs you might encounter:

* **Transaction Logs (Write-Ahead Logs - WAL):** These logs record all changes made to the database, typically before they are applied to the actual data files. This ensures that even if a failure occurs during a transaction, the database can be restored to a consistent state by replaying the completed transactions from the log.

* **Query Logs:** These logs track the SQL queries executed against the database. They can be used to analyze user activity, identify performance bottlenecks, and optimize queries for better efficiency.

* **Error Logs:** These logs record any errors or warnings that occur within the database system. This can include connection issues, syntax errors in SQL statements, or disk write failures. Analyzing error logs helps diagnose problems and take corrective actions.

* **Audit Logs:** These logs focus on security-related events, such as user login attempts, data access attempts, and permission changes. They provide a record of who accessed what data and when, which is crucial for maintaining database security and compliance with regulations.

Effective database logging is a critical practice for any organization that relies on databases. By implementing a proper logging strategy and regularly analyzing the logs, you can gain valuable insights into your database's health, security posture, and performance. This information can be used to optimize your database, troubleshoot issues, and ensure the integrity and availability of your data.